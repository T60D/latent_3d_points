{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "TensorFlow1",
      "language": "python",
      "name": "tf1"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.12"
    },
    "colab": {
      "name": "train_single_class_ae.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "d5I4m-Xr3Nnp"
      },
      "source": [
        "## This notebook will help you train a vanilla Point-Cloud AE with the basic architecture we used in our paper.\n",
        "    (it assumes latent_3d_points is in the PYTHONPATH and the structural losses have been compiled)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcSbKQVC3SRL",
        "outputId": "5ae7c610-418e-4102-bfb1-40e991dea101",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Setup environment to be compatible with colab\r\n",
        "!git clone https://github.com/T60D/latent_3d_points.git\r\n",
        "%tensorflow_version 1.x\r\n",
        "import sys\r\n",
        "import tensorflow\r\n",
        "print(tensorflow.__version__)\r\n",
        "\r\n",
        "!apt-get install -qq gcc-5 g++-5 -y &> /dev/null\r\n",
        "!ln -s /usr/bin/gcc-5 &> /dev/null\r\n",
        "!ln -s /usr/bin/g++-5 &> /dev/null\r\n",
        "\r\n",
        "!sudo apt-get update &> /dev/null\r\n",
        "!sudo apt-get upgrade &> /dev/null\r\n",
        "\r\n",
        "%cd /content/latent_3d_points/external/structural_losses\r\n",
        "!make"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'latent_3d_points' already exists and is not an empty directory.\n",
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.3`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n",
            "1.15.2\n",
            "/content/latent_3d_points/external/structural_losses\n",
            "make: Circular tf_approxmatch_g.cu <- tf_approxmatch_g.cu.o dependency dropped.\n",
            "make: Circular tf_nndistance_g.cu <- tf_nndistance_g.cu.o dependency dropped.\n",
            "make: Nothing to be done for 'all'.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIAIzmXz_sh3",
        "outputId": "757e0b11-2688-422d-bda1-ed3af7ba7750",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Import drive where the files are stored\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toNj7x0R_ozN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87lQ0jxB3Nns",
        "outputId": "bbcd380e-8308-427c-8aa9-276ed664ab7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd /content/\n",
        "\n",
        "import os.path as osp\n",
        "\n",
        "from latent_3d_points.src.ae_templates import mlp_architecture_ala_iclr_18, default_train_params\n",
        "from latent_3d_points.src.autoencoder import Configuration as Conf\n",
        "from latent_3d_points.src.point_net_ae import PointNetAutoEncoder\n",
        "\n",
        "from latent_3d_points.src.in_out import snc_category_to_synth_id, create_dir, PointCloudDataSet, \\\n",
        "                                        load_all_point_clouds_under_folder\n",
        "\n",
        "from latent_3d_points.src.tf_utils import reset_tf_graph\n",
        "from latent_3d_points.src.general_utils import plot_3d_point_cloud"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tflearn/helpers/summarizer.py:9: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tflearn/helpers/trainer.py:25: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tflearn/collections.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tflearn/config.py:123: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tflearn/config.py:129: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tflearn/config.py:131: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "External Losses (Chamfer-EMD) were not loaded.\n",
            "External Losses (Chamfer-EMD) cannot be loaded. Please install them first.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-z-LM2O3Nnt"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebXGAs3Q3Nnu"
      },
      "source": [
        "Define Basic Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59SAfoip3Nnu"
      },
      "source": [
        "top_out_dir = '/content/drive/Shareddrives/CS230/'          # Use to save Neural-Net check-points etc.\n",
        "top_in_dir = '/content/drive/Shareddrives/CS230/dev_data' # Top-dir of where point-clouds are stored.\n",
        "\n",
        "experiment_name = 'single_class_ae'\n",
        "n_pc_points = 2048                # Number of points per model.\n",
        "bneck_size = 128                  # Bottleneck-AE size\n",
        "ae_loss = 'chamfer'                   # Loss to optimize: 'emd' or 'chamfer'\n",
        "class_name = \"plane\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sh148KuN3Nnv"
      },
      "source": [
        "Load Point-Clouds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QdaucqN3Nnw",
        "outputId": "81e3b490-a120-4572-e780-f932b18c36d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "#syn_id = snc_category_to_synth_id()[class_name]\n",
        "#class_dir = osp.join(top_in_dir , syn_id)\n",
        "all_pc_data = load_all_point_clouds_under_folder(\"/content/drive/Shareddrives/CS230/dev_data\", n_threads=8, file_ending='.ply', verbose=True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-5ecb0a127196>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msyn_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msnc_category_to_synth_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#class_dir = osp.join(top_in_dir , syn_id)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mall_pc_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_all_point_clouds_under_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/Shareddrives/CS230/dev_data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_ending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'.ply'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'plane'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPJ5VoLW3Nnx"
      },
      "source": [
        "Load default training parameters (some of which are listed beloq). For more details please print the configuration object.\n",
        "\n",
        "    'batch_size': 50   \n",
        "    \n",
        "    'denoising': False     (# by default AE is not denoising)\n",
        "\n",
        "    'learning_rate': 0.0005\n",
        "\n",
        "    'z_rotate': False      (# randomly rotate models of each batch)\n",
        "    \n",
        "    'loss_display_step': 1 (# display loss at end of these many epochs)\n",
        "    'saver_step': 10       (# over how many epochs to save neural-network)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "EhpRgtMd3Nnx"
      },
      "source": [
        "train_params = default_train_params()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "K1PgiwL73Nny"
      },
      "source": [
        "encoder, decoder, enc_args, dec_args = mlp_architecture_ala_iclr_18(n_pc_points, bneck_size)\n",
        "train_dir = create_dir(osp.join(top_out_dir, experiment_name))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZkdbtVg3Nny",
        "outputId": "b059af58-a116-4fad-c911-63270f2f6fc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "source": [
        "conf = Conf(n_input = [n_pc_points, 3],\n",
        "            loss = ae_loss,\n",
        "            training_epochs = train_params['training_epochs'],\n",
        "            batch_size = train_params['batch_size'],\n",
        "            denoising = train_params['denoising'],\n",
        "            learning_rate = train_params['learning_rate'],\n",
        "            train_dir = train_dir,\n",
        "            loss_display_step = train_params['loss_display_step'],\n",
        "            saver_step = train_params['saver_step'],\n",
        "            z_rotate = train_params['z_rotate'],\n",
        "            encoder = encoder,\n",
        "            decoder = decoder,\n",
        "            encoder_args = enc_args,\n",
        "            decoder_args = dec_args\n",
        "           )\n",
        "conf.experiment_name = experiment_name\n",
        "conf.held_out_step = 5   # How often to evaluate/print out loss on \n",
        "                         # held_out data (if they are provided in ae.train() ).\n",
        "conf.save(osp.join(train_dir, 'configuration'))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-511b67b9e981>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheld_out_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m   \u001b[0;31m# How often to evaluate/print out loss on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                          \u001b[0;31m# held_out data (if they are provided in ae.train() ).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'configuration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/latent_3d_points/src/autoencoder.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, file_name)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mpickle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mfout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/latent_3d_points/src/autoencoder.py\u001b[0m in \u001b[0;36m__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'dict_values' object does not support indexing"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-Noq5d53Nnz"
      },
      "source": [
        "If you ran the above lines, you can reload a saved model like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80jmAaIV3Nnz"
      },
      "source": [
        "load_pre_trained_ae = False\n",
        "restore_epoch = 500\n",
        "if load_pre_trained_ae:\n",
        "    conf = Conf.load(train_dir + '/configuration')\n",
        "    reset_tf_graph()\n",
        "    ae = PointNetAutoEncoder(conf.experiment_name, conf)\n",
        "    ae.restore_model(conf.train_dir, epoch=restore_epoch)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7dXBZxy3Nn0"
      },
      "source": [
        "Build AE Model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNIY7V6F3Nn0",
        "outputId": "1304dd67-a2ce-4c57-9996-d1c5707d4117",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        }
      },
      "source": [
        "reset_tf_graph()\n",
        "ae = PointNetAutoEncoder(conf.experiment_name, conf)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/latent_3d_points/src/tf_utils.py:39: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/latent_3d_points/src/neural_net.py:17: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/latent_3d_points/src/neural_net.py:22: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/latent_3d_points/src/neural_net.py:24: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/latent_3d_points/src/autoencoder.py:99: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "Building Encoder\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-05f446b304ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mreset_tf_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPointNetAutoEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/latent_3d_points/src/point_net_ae.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, configuration, graph)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbottleneck_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/latent_3d_points/src/encoders_decoders.py\u001b[0m in \u001b[0;36mencoder_with_convs_and_symmetry\u001b[0;34m(in_signal, n_filters, filter_sizes, strides, b_norm, non_linearity, regularizer, weight_decay, symmetry, dropout_prob, pool, pool_sizes, scope, reuse, padding, verbose, closing, conv_op)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'More than 1 layers are expected.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_signal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'xrange' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avqDq59l3Nn0"
      },
      "source": [
        "Train the AE (save output to train_stats.txt) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMcP1yC63Nn1"
      },
      "source": [
        "buf_size = 1 # Make 'training_stats' file to flush each output line regarding training.\n",
        "fout = open(osp.join(conf.train_dir, 'train_stats.txt'), 'a', buf_size)\n",
        "train_stats = ae.train(all_pc_data, conf, log_file=fout)\n",
        "fout.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqsQ1p_T3Nn1"
      },
      "source": [
        "Get a batch of reconstuctions and their latent-codes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwKxMQ583Nn1"
      },
      "source": [
        "feed_pc, feed_model_names, _ = all_pc_data.next_batch(10)\n",
        "reconstructions = ae.reconstruct(feed_pc)[0]\n",
        "latent_codes = ae.transform(feed_pc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "xs3wQhkZ3Nn2"
      },
      "source": [
        "Use any plotting mechanism such as matplotlib to visualize the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjSYdFZe3Nn2"
      },
      "source": [
        "i = 2\n",
        "plot_3d_point_cloud(reconstructions[i][:, 0], \n",
        "                    reconstructions[i][:, 1], \n",
        "                    reconstructions[i][:, 2], in_u_sphere=True);\n",
        "\n",
        "i = 4\n",
        "plot_3d_point_cloud(reconstructions[i][:, 0], \n",
        "                    reconstructions[i][:, 1], \n",
        "                    reconstructions[i][:, 2], in_u_sphere=True);"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}